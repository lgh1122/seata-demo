# 安装kubernetes组件

## 生成集群CA证书

~~~powershell
mkdir /root/k8s-ssl
cd /root/k8s-ssl
[root@master k8s-ssl]# cat ca-csr.json
{
  "CN": "kubernetes",
  "key": {
    "algo": "rsa",
    "size": 2048
  },
  "names": [
    {
      "C": "CN",
      "L": "Beijing",
      "ST": "Beijing",
      "O": "k8s",
      "OU": "System"
    }
  ],
  "ca": {
    "expiry": "87600h"
  }
}

[root@master k8s-ssl]# cfssl gencert -initca ca-csr.json | cfssljson -bare ca
~~~

配置kube-apiserver证书

~~~powershell
# cat kube-apiserver-csr.json
{
  "CN": "kube-apiserver",
  "hosts": [
    "127.0.0.1",
    "192.168.0.20",
    "10.99.0.1",
    "kubernetes",
    "kubernetes.default",
    "kubernetes.default.svc",
    "kubernetes.default.svc.laiyuezs",
    "kubernetes.default.svc.laiyuezs.work"
  ],
  "key": {
    "algo": "rsa",
    "size": 2048
  },
  "names": [
    {
      "C": "CN",
      "L": "BeiJing",
      "ST": "BeiJing",
      "O": "k8s",
      "OU": "System"
    }
  ]
}

# cfssl gencert -ca=ca.pem -ca-key=ca-key.pem -config=/root/etcd-ssl/ca-config.json -profile=kubernetes kube-apiserver-csr.json | cfssljson -bare kube-apiserver
~~~

配置 kube-controller-manager 证书

~~~powershell
# cat kube-controller-manager-csr.json
{
  "CN": "system:kube-controller-manager",
  "hosts": [
    "127.0.0.1",
    "192.168.0.20"
  ],
  "key": {
    "algo": "rsa",
    "size": 2048
  },
  "names": [
    {
      "C": "CN",
      "L": "BeiJing",
      "ST": "BeiJing",
      "O": "system:kube-controller-manager",
      "OU": "System"
    }
  ]
}

# cfssl gencert -ca=ca.pem -ca-key=ca-key.pem -config=/root/etcd-ssl/ca-config.json -profile=kubernetes kube-controller-manager-csr.json | cfssljson -bare kube-controller-manager
~~~

配置 kube-scheduler 证书

~~~powershell
# cat kube-scheduler-csr.json
{
  "CN": "system:kube-scheduler",
  "hosts": [
    "127.0.0.1",
    "192.168.0.20"
  ],
  "key": {
    "algo": "rsa",
    "size": 2048
  },
  "names": [
    {
      "C": "CN",
      "L": "BeiJing",
      "ST": "BeiJing",
      "O": "system:kube-scheduler",
      "OU": "System"
    }
  ]
}

# cfssl gencert -ca=ca.pem -ca-key=ca-key.pem -config=/root/etcd-ssl/ca-config.json -profile=kubernetes kube-scheduler-csr.json | cfssljson -bare kube-scheduler
~~~

配置 kube-proxy 证书

该证书只会被 kube-proxy 当做 client 证书使用，所以 hosts 字段为空。

~~~powershell
# cat > kube-proxy-csr.json << EOF
{
  "CN": "system:kube-proxy",
  "key": {
    "algo": "rsa",
    "size": 2048
  },
  "names": [
    {
      "C": "CN",
      "L": "BeiJing",
      "ST": "BeiJing",
      "O": "system:kube-proxy",
      "OU": "System"
    }
  ]
}
EOF
# cfssl gencert -ca=ca.pem -ca-key=ca-key.pem -config=/root/etcd-ssl/ca-config.json -profile=kubernetes kube-proxy-csr.json | cfssljson -bare kube-proxy
~~~

配置 admin 证书

为集群组件 kubelet、kubectl 配置 admin TLS 认证证书，具有访问 kubernetes 所有 api 的
权限。

~~~powershell
# cat admin-csr.json
{
  "CN": "admin",
  "key": {
    "algo": "rsa",
    "size": 2048
  },
  "names": [
    {
      "C": "CN",
      "L": "BeiJing",
      "ST": "BeiJing",
      "O": "system:masters",
      "OU": "System"
    }
  ]
}

# cfssl gencert -ca=ca.pem -ca-key=ca-key.pem -config=/root/etcd-ssl/ca-config.json -profile=kubernetes admin-csr.json | cfssljson -bare admin
~~~

分发证书文件

提示： node 节点只需要 ca、kube-proxy、kubelet 证书，不需要拷贝 kube-controller-
manager、 kube-schedule、kube-apiserver 证书

~~~powershell
[root@master k8s-ssl] mkdir -pv /data/apps/kubernetes/{pki,log,etc,certs}
[root@master k8s-ssl] cp ca*.pem admin*.pem kube-proxy*.pem kube-scheduler*.pem kube-controller-manager*.pem kube-apiserver*.pem /data/apps/kubernetes/pki/

[root@master k8s-ssl] rsync -avzP /data/apps/kubernetes 192.168.0.21:/data/apps/
[root@master k8s-ssl] rsync -avzP /data/apps/kubernetes 192.168.0.22:/data/apps/

注意：192.168.0.21，192.168.0.22为node节点
~~~



## 部署MASTER

1.上传kubernetes-server-linux-amd64.tar.gz包并解压，如还有其他master节点，则也拷贝到其他节点上

~~~powershell
[root@master software]# tar zxf kubernetes-server-linux-amd64.tar.gz
[root@master software]# ll
total 534836
-rw-r--r-- 1 root root   9565743 Dec 20 17:40 flannel-v0.11.0-linux-amd64.tar.gz
drwxr-xr-x 4 root root        79 Aug 19 19:30 kubernetes
-rw-r--r-- 1 root root  94257559 Dec 20 17:40 kubernetes-node-linux-amd64.tar.gz
-rw-r--r-- 1 root root 443841740 Dec 20 17:40 kubernetes-server-linux-amd64.tar.gz
[root@master software]# cp -r kubernetes/server /data/apps/kubernetes/

拷贝kubernetes-node-linux-amd64.tar.gz到node节点
scp kubernetes-node-linux-amd64.tar.gz 192.168.0.21:/root
scp kubernetes-node-linux-amd64.tar.gz 192.168.0.22:/root
~~~

2.配置环境变量，安装docker命令补全

~~~powershell
# yum install bash-completion -y
# cat > /etc/profile.d/kubernetes.sh << EOF
K8S_HOME=/data/apps/kubernetes
export PATH=\$K8S_HOME/server/bin:\$PATH
source <(kubectl completion bash)
EOF
# source /etc/profile.d/kubernetes.sh
# kubectl version
~~~

3.配置TLS Bootstrapping

~~~powershell
# export BOOTSTRAP_TOKEN=$(head -c 16 /dev/urandom | od -An -t x | tr -d ' ')
# cat > /data/apps/kubernetes/token.csv << EOF
${BOOTSTRAP_TOKEN},kubelet-bootstrap,10001,"system:kubelet-bootstrap"
EOF
~~~

4.创建 kubelet bootstrapping kubeconfig

设置 kube-apiserver 访问地址， 如果需要对 kube-apiserver 配置高可用集群， 则这里设置apiserver 浮动 IP。  KUBE_APISERVER=浮动 IP，如果是单节点，则直接配置ip即可

~~~powershell
[root@master kubernetes]# cd /data/apps/kubernetes/

[root@master kubernetes]# export KUBE_APISERVER="https://192.168.0.20:6443"

# 设置集群参数
[root@master kubernetes]# kubectl config set-cluster kubernetes \
--certificate-authority=/data/apps/kubernetes/pki/ca.pem \
--embed-certs=true \
--server=${KUBE_APISERVER} \
--kubeconfig=kubelet-bootstrap.kubeconfig

# 设置客户端认证参数
[root@master kubernetes]# kubectl config set-credentials kubelet-bootstrap \
--token=${BOOTSTRAP_TOKEN} \
--kubeconfig=kubelet-bootstrap.kubeconfig

# 置上下文参数
[root@master kubernetes]# kubectl config set-context default \
--cluster=kubernetes \
--user=kubelet-bootstrap \
--kubeconfig=kubelet-bootstrap.kubeconfig

# 设置默认上下文
[root@master kubernetes]# kubectl config use-context default --kubeconfig=kubelet-bootstrap.kubeconfig

~~~

5.创建 kube-controller-manager kubeconfig

~~~powershell
[root@master kubernetes]# kubectl config set-cluster kubernetes \
--certificate-authority=/data/apps/kubernetes/pki/ca.pem \
--embed-certs=true \
--server=${KUBE_APISERVER} \
--kubeconfig=kube-controller-manager.kubeconfig

[root@master kubernetes]# kubectl config set-credentials kube-controller-manager \
--client-certificate=/data/apps/kubernetes/pki/kube-controller-manager.pem \
--client-key=/data/apps/kubernetes/pki/kube-controller-manager-key.pem \
--embed-certs=true \
--kubeconfig=kube-controller-manager.kubeconfig

[root@master kubernetes]# kubectl config set-context default \
--cluster=kubernetes \
--user=kube-controller-manager \
--kubeconfig=kube-controller-manager.kubeconfig

[root@master kubernetes]# kubectl config use-context default --kubeconfig=kube-controller-manager.kubeconfig
~~~

6.创建 kube-scheduler kubeconfig

~~~powershell
[root@master kubernetes]# kubectl config set-cluster kubernetes \
--certificate-authority=/data/apps/kubernetes/pki/ca.pem \
--embed-certs=true \
--server=${KUBE_APISERVER} \
--kubeconfig=kube-scheduler.kubeconfig

[root@master kubernetes]# kubectl config set-credentials kube-scheduler \
--client-certificate=/data/apps/kubernetes/pki/kube-scheduler.pem \
--client-key=/data/apps/kubernetes/pki/kube-scheduler-key.pem \
--embed-certs=true \
--kubeconfig=kube-scheduler.kubeconfig

[root@master kubernetes]# kubectl config set-context default \
--cluster=kubernetes \
--user=kube-scheduler \
--kubeconfig=kube-scheduler.kubeconfig

[root@master kubernetes]# kubectl config use-context default --kubeconfig=kube-scheduler.kubeconfig
~~~

7.创建 kube-proxy kubeconfig

~~~powershell
[root@master kubernetes]# kubectl config set-cluster kubernetes \
--certificate-authority=/data/apps/kubernetes/pki/ca.pem \
--embed-certs=true \
--server=${KUBE_APISERVER} \
--kubeconfig=kube-proxy.kubeconfig

[root@master kubernetes]# kubectl config set-credentials kube-proxy \
--client-certificate=/data/apps/kubernetes/pki/kube-proxy.pem \
--client-key=/data/apps/kubernetes/pki/kube-proxy-key.pem \
--embed-certs=true \
--kubeconfig=kube-proxy.kubeconfig

[root@master kubernetes]# kubectl config set-context default \
--cluster=kubernetes \
--user=kube-proxy \
--kubeconfig=kube-proxy.kubeconfig

[root@master kubernetes]# kubectl config use-context default --kubeconfig=kube-proxy.kubeconfig
~~~

8.创建 admin kubeconfig

~~~powershell
[root@master kubernetes]# kubectl config set-cluster kubernetes \
--certificate-authority=/data/apps/kubernetes/pki/ca.pem \
--embed-certs=true \
--server=${KUBE_APISERVER} \
--kubeconfig=admin.conf

[root@master kubernetes]# kubectl config set-credentials admin \
--client-certificate=/data/apps/kubernetes/pki/admin.pem \
--client-key=/data/apps/kubernetes/pki/admin-key.pem \
--embed-certs=true \
--kubeconfig=admin.conf

[root@master kubernetes]# kubectl config set-context default \
--cluster=kubernetes \
--user=admin \
--kubeconfig=admin.conf

[root@master kubernetes]# kubectl config use-context default --kubeconfig=admin.conf
~~~

9.分发 kubelet/kube-proxy 配置文件

9.1分发配置文件到 node 节点

~~~powershell
[root@master kubernetes]# mv kube* token.csv admin.conf etc/
[root@master kubernetes]# rsync -avz --exclude=kube-scheduler.kubeconfig --exclude=kube-controller-manager.kubeconfig --exclude=admin.conf --exclude=token.csv etc 192.168.0.21:/data/apps/kubernetes

[root@master kubernetes]# rsync -avz --exclude=kube-scheduler.kubeconfig --exclude=kube-controller-manager.kubeconfig --exclude=admin.conf --exclude=token.csv etc 192.168.0.22:/data/apps/kubernetes
~~~



9.2分发配置文件到其他 master 节点

......

10.配置 kube-apiserver

~~~powershell
# cd /data/apps/kubernetes/pki/
# openssl genrsa -out /data/apps/kubernetes/pki/sa.key 2048
# openssl rsa -in /data/apps/kubernetes/pki/sa.key -pubout -out /data/apps/kubernetes/pki/sa.pub
~~~

分发文件到其他apiserver节点(没有则省略)

~~~powershell
scp -r /data/apps/kubernetes/pki/sa.* *.*.*.*:/data/apps/kubernetes/pki/
scp -r /data/apps/kubernetes/etc *.*.*.*:/data/apps/kubernetes/

~~~

11 配置 apiserver 系统服务

11.1 系统服务文件

~~~powershell
# cat > /usr/lib/systemd/system/kube-apiserver.service << EOF
[Unit]
Description=Kubernetes API Service
Documentation=https://github.com/kubernetes/kubernetes
After=network.target
[Service]
EnvironmentFile=-/data/apps/kubernetes/etc/kube-apiserver.conf
ExecStart=/data/apps/kubernetes/server/bin/kube-apiserver \\
\$KUBE_LOGTOSTDERR \\
\$KUBE_LOG_LEVEL \\
\$KUBE_ETCD_ARGS \\
\$KUBE_API_ADDRESS \\
\$KUBE_SERVICE_ADDRESSES \\
\$KUBE_ADMISSION_CONTROL \\
\$KUBE_APISERVER_ARGS
Restart=on-failure
Type=notify
LimitNOFILE=65536
[Install]
WantedBy=multi-user.target
EOF
~~~

11.2 配置文件

~~~powershell
# cat > /data/apps/kubernetes/etc/kube-apiserver.conf << EOF
KUBE_API_ADDRESS="--advertise-address=192.168.0.20"
KUBE_ETCD_ARGS="--etcd-servers=https://192.168.0.20:2379,https://192.168.0.21:2379,https://192.168.0.22:2379 \
--etcd-cafile=/data/apps/etcd/ssl/etcd-ca.pem \
--etcd-certfile=/data/apps/etcd/ssl/etcd.pem \
--etcd-keyfile=/data/apps/etcd/ssl/etcd-key.pem"
KUBE_LOGTOSTDERR="--logtostderr=false"
KUBE_LOG_LEVEL="--log-dir=/data/apps/kubernetes/log/ --v=2 \
--audit-log-maxage=7 \
--audit-log-maxbackup=10 \
--audit-log-maxsize=100 \
--audit-log-path=/data/apps/kubernetes/log/kubernetes.audit --event-ttl=12h"
KUBE_SERVICE_ADDRESSES="--service-cluster-ip-range=10.99.0.0/16"
KUBE_ADMISSION_CONTROL="--enable-admission-plugins=NamespaceLifecycle,LimitRanger,ServiceAccount,DefaultStorageClass,DefaultTolerationSeconds,MutatingAdmissionWebhook,ValidatingAdmissionWebhook,ResourceQuota,PersistentVolumeClaimResize,PodPreset"
KUBE_APISERVER_ARGS="--storage-backend=etcd3 \
--apiserver-count=1 \
--endpoint-reconciler-type=lease \
--runtime-config=api/all,settings.k8s.io/v1alpha1=true,admissionregistration.k8s.io/v1beta1 \
--allow-privileged=true \
--authorization-mode=Node,RBAC \
--enable-bootstrap-token-auth=true \
--token-auth-file=/data/apps/kubernetes/etc/token.csv \
--service-node-port-range=30000-40000 \
--tls-cert-file=/data/apps/kubernetes/pki/kube-apiserver.pem \
--tls-private-key-file=/data/apps/kubernetes/pki/kube-apiserver-key.pem \
--client-ca-file=/data/apps/kubernetes/pki/ca.pem \
--service-account-key-file=/data/apps/kubernetes/pki/sa.pub \
--enable-swagger-ui=false \
--secure-port=6443 \
--kubelet-preferred-address-types=InternalIP,ExternalIP,Hostname \
--anonymous-auth=false \
--kubelet-client-certificate=/data/apps/kubernetes/pki/admin.pem \
--kubelet-client-key=/data/apps/kubernetes/pki/admin-key.pem "
EOF

--tls-cert-file=/data/apps/kubernetes/pki/kube-apiserver.pem  
--tls-private-key-file=/data/apps/kubernetes/pki/kube-apiserver-key.pem
作为服务器端，必须要准备好自己的证书(对)，所以这两个参数就是指定了证书的路径。
--client-ca-file
这个参数的含义是指定客户端使用的根证书的路径。一旦设置了，那么你在访问api的时候一定得带上使用该根证书签发的公钥/私钥对
--service-account-key-file
该参数表示的含义是公钥的路径，它与kube-controller-manager的--service-account-private-key-file是对应关系，因为pod带着token去访问api server，则api server要能解密才行，所以同时还需要在api那里配置，当然如果不配置，不影响pod创建，只不过在pod里访问api的时候就不行了。
~~~

11.3 启动所有apiserver

~~~powershell
# systemctl daemon-reload
# systemctl enable kube-apiserver
# systemctl start kube-apiserver
# systemctl status kube-apiserver


注意：启动时会出错，Error: enable-admission-plugins plugin "Initializers" is unknown
所以删除了--enable-admission-plugins=Initializers

# 测试是否可以访问
# curl -k https://192.168.0.20:6443
{
  "kind": "Status",
  "apiVersion": "v1",
  "metadata": {
    
  },
  "status": "Failure",
  "message": "Unauthorized",
  "reason": "Unauthorized",
  "code": 401
}
~~~

12 配置启动 kube-controller-manager

kube-controller-manager  负责维护集群的状态，比如故障检测、自动扩展、滚动更新等
在启动时设置  --leader-elect=true 后， controller manager 会使用多节点选主的方式选择主节点。只有主节点才会调用  StartControllers() 启动所有控制器，而其他从节点则仅执行选主算法。

~~~powershell
# 创建系统服务文件
# cat > /usr/lib/systemd/system/kube-controller-manager.service << EOF
Description=Kubernetes Controller Manager
Documentation=https://github.com/kubernetes/kubernetes
[Service]
EnvironmentFile=-/data/apps/kubernetes/etc/kube-controller-manager.conf
ExecStart=/data/apps/kubernetes/server/bin/kube-controller-manager \\
\$KUBE_LOGTOSTDERR \\
\$KUBE_LOG_LEVEL \\
\$KUBECONFIG \\
\$KUBE_CONTROLLER_MANAGER_ARGS
Restart=always
RestartSec=10s
#Restart=on-failure
LimitNOFILE=65536
[Install]
WantedBy=multi-user.target
EOF

# 创建配置文件
# cat > /data/apps/kubernetes/etc/kube-controller-manager.conf << EOF
KUBE_LOGTOSTDERR="--logtostderr=false"
KUBE_LOG_LEVEL="--v=2 --log-dir=/data/apps/kubernetes/log/"
KUBECONFIG="--kubeconfig=/data/apps/kubernetes/etc/kube-controller-manager.kubeconfig"
KUBE_CONTROLLER_MANAGER_ARGS="--bind-address=127.0.0.1 \
--cluster-cidr=10.244.0.0/16 \
--cluster-name=kubernetes \
--cluster-signing-cert-file=/data/apps/kubernetes/pki/ca.pem \
--cluster-signing-key-file=/data/apps/kubernetes/pki/ca-key.pem \
--service-account-private-key-file=/data/apps/kubernetes/pki/sa.key \
--root-ca-file=/data/apps/kubernetes/pki/ca.pem \
--leader-elect=true \
--use-service-account-credentials=true \
--node-monitor-grace-period=100s \
--pod-eviction-timeout=100s \
--allocate-node-cidrs=true \
--controllers=*,bootstrapsigner,tokencleaner \
--horizontal-pod-autoscaler-use-rest-clients=true \
--experimental-cluster-signing-duration=87600h0m0s \
--feature-gates=RotateKubeletServerCertificate=true"
EOF

--service-account-private-key-file
该参数表示的含义是私钥的路径，它的作用是给服务账号产生token，之后pod就可以拿着这个token去访问api server了。

--root-ca-file
该参数会给服务账号一个根证书ca.pem，可选配置，如果配置成给api server签发证书的那个根证书，那就可以拿来用于认证api server。

# 启动 kube-controller-manager
# systemctl daemon-reload
# systemctl enable kube-controller-manager
# systemctl start kube-controller-manager
# systemctl status kube-controller-manager

~~~

13.配置kubectl

~~~powershell
# rm -rf $HOME/.kube
# mkdir -p $HOME/.kube
# cp /data/apps/kubernetes/etc/admin.conf $HOME/.kube/config
# sudo chown $(id -u):$(id -g) $HOME/.kube/config
# kubectl get node
# kubectl get componentstatuses

~~~

14.配置kubelet 使用 bootstrap

~~~powershell
# kubectl create clusterrolebinding kubelet-bootstrap \
--clusterrole=system:node-bootstrapper \
--user=kubelet-bootstrap
~~~

15.配置启动 kube-scheduler

kube-scheduler 负责分配调度 Pod 到集群内的节点上，它监听 kube-apiserver，查询还未分配 Node 的 Pod，然后根据调度策略为这些 Pod 分配节点。按照预定的调度策略将Pod 调度到相应的机器上（更新 Pod 的NodeName 字段）。

~~~powershell
# 创建系统服务文件
# cat > /usr/lib/systemd/system/kube-scheduler.service << EOF
[Unit]
Description=Kubernetes Scheduler Plugin
Documentation=https://github.com/kubernetes/kubernetes
[Service]
EnvironmentFile=-/data/apps/kubernetes/etc/kube-scheduler.conf
ExecStart=/data/apps/kubernetes/server/bin/kube-scheduler \\
\$KUBE_LOGTOSTDERR \\
\$KUBE_LOG_LEVEL \\
\$KUBECONFIG \\
\$KUBE_SCHEDULER_ARGS
Restart=on-failure
LimitNOFILE=65536
[Install]
WantedBy=multi-user.target
EOF


# 创建 kube-scheduler.conf 配置文件
# cat > /data/apps/kubernetes/etc/kube-scheduler.conf<< EOF
KUBE_LOGTOSTDERR="--logtostderr=false"
KUBE_LOG_LEVEL="--v=2 --log-dir=/data/apps/kubernetes/log/"
KUBECONFIG="--kubeconfig=/data/apps/kubernetes/etc/kube-scheduler.kubeconfig"
KUBE_SCHEDULER_ARGS="--address=127.0.0.1"
EOF

# 启动 kube-scheduler， 并设置服务开机自启动
# systemctl daemon-reload
# systemctl enable kube-scheduler
# systemctl start kube-scheduler
# systemctl status kube-scheduler
~~~



## 部署Node

1. 配置 kubelet

kubelet 负责维持容器的生命周期，同时也负责 Volume（CVI）和网络（CNI）的管理；每个节点上都运行一个 kubelet 服务进程，默认监听 10250 端口，接收并执行 master 发来的指令，管理 Pod 及 Pod 中的容器。每个 kubelet 进程会在 API Server 上注册节点自身信息，定期向 master 节点汇报节点的资源使用情况，并通过 cAdvisor/metric-server 监控节点和容器的资源。

配置并启动 kubelet， flanneld (master 与 node 节点都需要安装)
在 ==Master 节点==配置 kubelet

~~~powershell
# 创建服务文件
# cat > /usr/lib/systemd/system/kubelet.service << EOF
[Unit]
Description=Kubernetes Kubelet Server
Documentation=https://github.com/kubernetes/kubernetes
After=docker.service
Requires=docker.service
[Service]
EnvironmentFile=-/data/apps/kubernetes/etc/kubelet.conf
ExecStart=/data/apps/kubernetes/server/bin/kubelet \\
\$KUBE_LOGTOSTDERR \\
\$KUBE_LOG_LEVEL \\
\$KUBELET_CONFIG \\
\$KUBELET_HOSTNAME \\
\$KUBELET_POD_INFRA_CONTAINER \\
\$KUBELET_ARGS
Restart=on-failure
[Install]
WantedBy=multi-user.target
EOF

# 创建 kubelet 配置文件
# cat > /data/apps/kubernetes/etc/kubelet.conf << EOF
KUBE_LOGTOSTDERR="--logtostderr=false"
KUBE_LOG_LEVEL="--v=2 --log-dir=/data/apps/kubernetes/log/"
KUBELET_HOSTNAME="--hostname-override=192.168.0.20"
KUBELET_POD_INFRA_CONTAINER="--pod-infra-container-image=registry.cn-hangzhou.aliyuncs.com/google_containers/pause-amd64:3.1"
KUBELET_CONFIG="--config=/data/apps/kubernetes/etc/kubelet-config.yml"
KUBELET_ARGS="--bootstrap-kubeconfig=/data/apps/kubernetes/etc/kubelet-bootstrap.kubeconfig --kubeconfig=/data/apps/kubernetes/etc/kubelet.kubeconfig --cert-dir=/data/apps/kubernetes/pki --feature-gates=RotateKubeletClientCertificate=true"
EOF

注意kubelet.kubeconfig该文件，没有生成

# cat > /data/apps/kubernetes/etc/kubelet-config.yml << EOF
kind: KubeletConfiguration
apiVersion: kubelet.config.k8s.io/v1beta1
address: 192.168.0.20
port: 10250
cgroupDriver: cgroupfs
clusterDNS:
- 10.99.110.110
clusterDomain: laiyuezs.work.
hairpinMode: promiscuous-bridge
maxPods: 200
failSwapOn: false
imageGCHighThresholdPercent: 90
imageGCLowThresholdPercent: 80
imageMinimumGCAge: 5m0s
serializeImagePulls: false
authentication:
  x509:
    clientCAFile: /data/apps/kubernetes/pki/ca.pem
  anonymous:
    enbaled: false
  webhook:
    enbaled: false
EOF
~~~

在Node1节点上配置 kubelet

~~~powershell
# cd /opt/software
# tar zxf kubernetes-node-linux-amd64.tar.gz
# mv kubernetes/node /data/apps/kubernetes/

# 系统服务文件
# cat > /usr/lib/systemd/system/kubelet.service << EOF
[Unit]
Description=Kubernetes Kubelet Server
Documentation=https://github.com/kubernetes/kubernetes
After=docker.service
Requires=docker.service
[Service]
EnvironmentFile=-/data/apps/kubernetes/etc/kubelet.conf
ExecStart=/data/apps/kubernetes/node/bin/kubelet \\
\$KUBE_LOGTOSTDERR \\
\$KUBE_LOG_LEVEL \\
\$KUBELET_CONFIG \\
\$KUBELET_HOSTNAME \\
\$KUBELET_POD_INFRA_CONTAINER \\
\$KUBELET_ARGS
Restart=on-failure
[Install]
WantedBy=multi-user.target
EOF

# 配置文件
# cat > /data/apps/kubernetes/etc/kubelet.conf << EOF
KUBE_LOGTOSTDERR="--logtostderr=false"
KUBE_LOG_LEVEL="--v=2 --log-dir=/data/apps/kubernetes/log/"
KUBELET_HOSTNAME="--hostname-override=192.168.0.21"
KUBELET_POD_INFRA_CONTAINER="--pod-infra-container-image=registry.cn-hangzhou.aliyuncs.com/google_containers/pause-amd64:3.1"
KUBELET_CONFIG="--config=/data/apps/kubernetes/etc/kubelet-config.yml"
KUBELET_ARGS="--bootstrap-kubeconfig=/data/apps/kubernetes/etc/kubelet-bootstrap.kubeconfig --kubeconfig=/data/apps/kubernetes/etc/kubelet.kubeconfig --cert-dir=/data/apps/kubernetes/pki"
EOF

# cat > /data/apps/kubernetes/etc/kubelet-config.yml << EOF
kind: KubeletConfiguration
apiVersion: kubelet.config.k8s.io/v1beta1
address: 192.168.0.21
port: 10250
cgroupDriver: cgroupfs
clusterDNS:
  - 10.99.110.110
clusterDomain: laiyuezs.work.
hairpinMode: promiscuous-bridge
maxPods: 200
failSwapOn: false
imageGCHighThresholdPercent: 90
imageGCLowThresholdPercent: 80
imageMinimumGCAge: 5m0s
serializeImagePulls: false
authentication:
  x509:
    clientCAFile: /data/apps/kubernetes/pki/ca.pem
  anonymous:
    enbaled: false
  webhook:
    enbaled: false
EOF

# node1启动kubelet
# systemctl daemon-reload
# systemctl enable kubelet
# systemctl restart kubelet
# systemctl status kubelet
~~~

在Node2节点上配置 kubelet

~~~powershell
# cd /opt/software
# tar zxf kubernetes-node-linux-amd64.tar.gz
# mv kubernetes/node /data/apps/kubernetes/

# 系统服务文件
# cat > /usr/lib/systemd/system/kubelet.service << EOF
[Unit]
Description=Kubernetes Kubelet Server
Documentation=https://github.com/kubernetes/kubernetes
After=docker.service
Requires=docker.service
[Service]
EnvironmentFile=-/data/apps/kubernetes/etc/kubelet.conf
ExecStart=/data/apps/kubernetes/node/bin/kubelet \\
\$KUBE_LOGTOSTDERR \\
\$KUBE_LOG_LEVEL \\
\$KUBELET_CONFIG \\
\$KUBELET_HOSTNAME \\
\$KUBELET_POD_INFRA_CONTAINER \\
\$KUBELET_ARGS
Restart=on-failure
[Install]
WantedBy=multi-user.target
EOF

# 配置文件
# cat > /data/apps/kubernetes/etc/kubelet.conf << EOF
KUBE_LOGTOSTDERR="--logtostderr=false"
KUBE_LOG_LEVEL="--v=2 --log-dir=/data/apps/kubernetes/log/"
KUBELET_HOSTNAME="--hostname-override=192.168.0.22"
KUBELET_POD_INFRA_CONTAINER="--pod-infra-container-image=registry.cn-hangzhou.aliyuncs.com/google_containers/pause-amd64:3.1"
KUBELET_CONFIG="--config=/data/apps/kubernetes/etc/kubelet-config.yml"
KUBELET_ARGS="--bootstrap-kubeconfig=/data/apps/kubernetes/etc/kubelet-bootstrap.kubeconfig --kubeconfig=/data/apps/kubernetes/etc/kubelet.kubeconfig --cert-dir=/data/apps/kubernetes/pki"
EOF

# cat > /data/apps/kubernetes/etc/kubelet-config.yml << EOF
kind: KubeletConfiguration
apiVersion: kubelet.config.k8s.io/v1beta1
address: 192.168.0.22
port: 10250
cgroupDriver: cgroupfs
clusterDNS:
  - 10.99.110.110
clusterDomain: laiyuezs.work.
hairpinMode: promiscuous-bridge
maxPods: 200
failSwapOn: false
imageGCHighThresholdPercent: 90
imageGCLowThresholdPercent: 80
imageMinimumGCAge: 5m0s
serializeImagePulls: false
authentication:
  x509:
    clientCAFile: /data/apps/kubernetes/pki/ca.pem
  anonymous:
    enbaled: false
  webhook:
    enbaled: false
EOF

# node2启动kubelet
# systemctl daemon-reload
# systemctl enable kubelet
# systemctl restart kubelet
# systemctl status kubelet
~~~

2. 配置 kube-proxy

kube-proxy 负责为 Service 提供 cluster 内部的服务发现和负载均衡；每台机器上都运行一个 kube-proxy 服务，它监听 API server 中 service和 endpoint 的变化情况，并通过 ipvs/iptables 等来为服务配置负载均衡（仅支持 TCP 和 UDP）。

注意：使用 ipvs 模式时，需要预先在每台 Node 上加载内核模块nf_conntrack_ipv4, ip_vs, ip_vs_rr, ip_vs_wrr, ip_vs_sh 等。

master节点上操作

~~~powershell
安装 conntrack-tools
# yum install -y conntrack-tools ipvsadm ipset conntrack libseccomp

创建服务启动文件
# cat > /usr/lib/systemd/system/kube-proxy.service << EOF
[Unit]
Description=Kubernetes Kube-Proxy Server
Documentation=https://github.com/kubernetes/kubernetes
After=network.target
[Service]
EnvironmentFile=-/data/apps/kubernetes/etc/kube-proxy.conf
ExecStart=/data/apps/kubernetes/server/bin/kube-proxy \\
\$KUBE_LOGTOSTDERR \\
\$KUBE_LOG_LEVEL \\
\$KUBECONFIG \\
\$KUBE_PROXY_ARGS
Restart=on-failure
LimitNOFILE=65536
KillMode=process
[Install]
WantedBy=multi-user.target
EOF
~~~

启用 ipvs 主要就是把 kube-proxy 的--proxy-mode 配置选项修改为 ipvs,并且要启用--masquerade-all，使用 iptables 辅助 ipvs 运行。

~~~powershell
创建配置文件
# cat > /data/apps/kubernetes/etc/kube-proxy.conf << EOF
KUBE_LOGTOSTDERR="--logtostderr=false"
KUBE_LOG_LEVEL="--v=2 --log-dir=/data/apps/kubernetes/log/"
KUBECONFIG="--kubeconfig=/data/apps/kubernetes/etc/kube-proxy.kubeconfig"
KUBE_PROXY_ARGS="--proxy-mode=ipvs --masquerade-all=true --cluster-cidr=10.244.0.0/16"
EOF

# 启动 kube-proxy 并设置为开机自启动
# systemctl daemon-reload
# systemctl enable kube-proxy
# systemctl start kube-proxy
# systemctl status kube-proxy
~~~

在所有Node上操作

~~~powershell
安装 conntrack-tools
# yum install -y conntrack-tools ipvsadm ipset conntrack libseccomp

创建服务启动文件
# cat > /usr/lib/systemd/system/kube-proxy.service << EOF
[Unit]
Description=Kubernetes Kube-Proxy Server
Documentation=https://github.com/kubernetes/kubernetes
After=network.target
[Service]
EnvironmentFile=-/data/apps/kubernetes/etc/kube-proxy.conf
ExecStart=/data/apps/kubernetes/node/bin/kube-proxy \\
\$KUBE_LOGTOSTDERR \\
\$KUBE_LOG_LEVEL \\
\$KUBECONFIG \\
\$KUBE_PROXY_ARGS
Restart=on-failure
LimitNOFILE=65536
[Install]
WantedBy=multi-user.target
EOF

创建配置文件
# cat > /data/apps/kubernetes/etc/kube-proxy.conf << EOF
KUBE_LOGTOSTDERR="--logtostderr=false"
KUBE_LOG_LEVEL="--v=2 --log-dir=/data/apps/kubernetes/log/"
KUBECONFIG="--kubeconfig=/data/apps/kubernetes/etc/kube-proxy.kubeconfig"
KUBE_PROXY_ARGS="--proxy-mode=ipvs --masquerade-all=true --cluster-cidr=10.244.0.0/16"
EOF

# 启动 kube-proxy 并设置为开机自启动
# systemctl daemon-reload
# systemctl enable kube-proxy
# systemctl start kube-proxy
# systemctl status kube-proxy


~~~

3.通过证书验证添加各个节点

~~~powershell
在 master 节点操作
[root@master etc]# kubectl get csr
NAME                                                   AGE   REQUESTOR           CONDITION
node-csr-5eGOzmAXliEO2uarHLkwlIT2fBgUAmUsxsI3SoY7hqc   18m   kubelet-bootstrap   Pending
node-csr-npkuftNKggSsORCKqhipwybQXrn7kpxCpb2SX1Gfbo4   18m   kubelet-bootstrap   Pending
node-csr-sWDUOicJsl2N-4BL8zWrXpQZs9xSiUKgsJ5-17sLUgQ   18m   kubelet-bootstrap   Pending

通过验证并添加进集群
[root@master etc]# kubectl get csr | awk '/node/{print $1}' | xargs kubectl certificate approve
certificatesigningrequest.certificates.k8s.io/node-csr-5eGOzmAXliEO2uarHLkwlIT2fBgUAmUsxsI3SoY7hqc approved
certificatesigningrequest.certificates.k8s.io/node-csr-npkuftNKggSsORCKqhipwybQXrn7kpxCpb2SX1Gfbo4 approved
certificatesigningrequest.certificates.k8s.io/node-csr-sWDUOicJsl2N-4BL8zWrXpQZs9xSiUKgsJ5-17sLUgQ approved

查看节点
[root@master etc]# kubectl get nodes 
NAME           STATUS   ROLES    AGE    VERSION
192.168.0.20   Ready    <none>   121m   v1.15.3
192.168.0.21   Ready    <none>   80m    v1.15.3
192.168.0.22   Ready    <none>   80m    v1.15.3

设置集群角色
# kubectl label nodes 192.168.0.20 node-role.kubernetes.io/master=MASTER-1
# kubectl label nodes 192.168.0.21 node-role.kubernetes.io/node=NODE-1
# kubectl label nodes 192.168.0.22 node-role.kubernetes.io/node=NODE-2

设置 master 一般情况下不接受负载
kubectl taint nodes 192.168.0.20 node-role.kubernetes.io/master=MASTER-1:NoSchedule --overwrite

此时查看节点 Roles, ROLES 已经标识出了 master 和 node
[root@master etc]# kubectl get nodes 
NAME           STATUS   ROLES    AGE    VERSION
192.168.0.20   Ready    master   126m   v1.15.3
192.168.0.21   Ready    node     85m    v1.15.3
192.168.0.22   Ready    node     85m    v1.15.3
~~~

4. 配置网络插件

Master 和 node 节点

~~~powershell
# cd /opt/software/
# tar zxvf flannel-v0.11.0-linux-amd64.tar.gz
# mv flanneld mk-docker-opts.sh /data/apps/kubernetes/server/bin/
# chmod +x /data/apps/kubernetes/server/bin/*

node节点
# mv flanneld mk-docker-opts.sh /data/apps/kubernetes/node/bin/
# chmod +x /data/apps/kubernetes/node/bin/*
~~~

4.1 创建 flanneld.conf 配置文件

创建网络段

~~~powershell
#在 etcd 集群执行如下命令， 为 docker 创建互联网段
# /data/apps/etcd/bin/etcdctl --ca-file=/data/apps/etcd/ssl/etcd-ca.pem --cert-file=/data/apps/etcd/ssl/etcd.pem --key-file=/data/apps/etcd/ssl/etcd-key.pem --endpoints="https://192.168.0.20:2379,https://192.168.0.21:2379,https://192.168.0.22:2379" set /coreos.com/network/config '{ "Network": "10.244.0.0/16", "Backend": {"Type": "vxlan"}}'
~~~

在 node 节点创建 etcd 证书存放路径， 并拷贝 etcd 证书到 Node 节点，

~~~powershell
注意：我这里node节点也是etcd节点，所有可以省略
# mkdir -p /data/apps/etcd
# scp -r /data/apps/etcd/ssl 192.168.0.21:/data/apps/etcd/
# scp -r /data/apps/etcd/ssl 192.168.0.22:/data/apps/etcd/
~~~

创建 flannel 配置文件

~~~powershell
# cat > /data/apps/kubernetes/etc/flanneld.conf << EOF
FLANNEL_OPTIONS="--etcd-endpoints=https://192.168.0.20:2379,https://192.168.0.21:2379,https://192.168.0.22:2379 -etcd-cafile=/data/apps/etcd/ssl/etcd-ca.pem -etcd-certfile=/data/apps/etcd/ssl/etcd.pem -etcd-keyfile=/data/apps/etcd/ssl/etcd-key.pem"
EOF
~~~

4.2 创建系统服务

~~~powershell
# cat > /usr/lib/systemd/system/flanneld.service << EOF
[Unit]
Description=Flanneld overlay address etcd agent
After=network-online.target network.target
Before=docker.service
[Service]
Type=notify
EnvironmentFile=/data/apps/kubernetes/etc/flanneld.conf
ExecStart=/data/apps/kubernetes/server/bin/flanneld --ip-masq \$FLANNEL_OPTIONS
ExecStartPost=/data/apps/kubernetes/server/bin/mk-docker-opts.sh -k DOCKER_NETWORK_OPTIONS -d /run/flannel/subnet.env
Restart=on-failure
[Install]
WantedBy=multi-user.target
EOF
~~~

注意： master 节点的 flanneld 服务配置文件 /node/bin/ 需要改为/server/bin/

4.3 修改 docker.service 启动文件

添加子网配置文件

~~~powershell
# vim /usr/lib/systemd/system/docker.service
# --graph 表示修改 docker 默认/var/lib/docker 存储路径为/data/docker , 需提前创建目录
EnvironmentFile=/run/flannel/subnet.env
ExecStart=/usr/bin/dockerd -H unix:// $DOCKER_NETWORK_OPTIONS $DOCKER_DNS_OPTIONS
~~~

修改 docker 服务启动文件，注入 dns 参数

~~~powershell
# mkdir -p /usr/lib/systemd/system/docker.service.d/
# vim /usr/lib/systemd/system/docker.service.d/docker-dns.conf
[Service]
Environment="DOCKER_DNS_OPTIONS=--dns 100.100.2.136 --dns 100.100.2.138 --dns-search default.svc.laiyuezs.work --dns-search svc.laiyuezs.work --dns-opt ndots:2 --dns-opt timeout:2 --dns-opt attempts:2"
~~~

4.4 启动 flanneld

~~~powershell
# systemctl daemon-reload
# systemctl start flanneld
# systemctl restart docker
# systemctl status flanneld
~~~

5.配置 coredns(master节点上操作)

~~~powershell
# 10.99.110.110 是 kubelet 中配置的 dns
# 安装 coredns
# cd /root && mkdir coredns && cd coredns
# wget https://raw.githubusercontent.com/coredns/deployment/master/kubernetes/coredns.yaml.sed
# wget https://raw.githubusercontent.com/coredns/deployment/master/kubernetes/deploy.sh
# chmod +x deploy.sh

# ./deploy.sh -s -r 10.99.0.0/16 -i 10.99.110.110 -d laiyuezs.work > coredns.yml
# kubectl apply -f coredns.yml

#查看 coredns 是否运行正常
# kubectl get svc,pods -n kube-system
~~~



6.配置dashboard(master节点上操作)

~~~powershell
cd /root && mkdir dashboard && cd dashboard
curl -O https://soft.8090st.com/kubernetes/dashboard/kubernetes-dashboard.yaml

生成证书
openssl genrsa -des3 -passout pass:x -out dashboard.pass.key 2048
openssl rsa -passin pass:x -in dashboard.pass.key -out dashboard.key
rm dashboard.pass.key -rf
openssl req -new -key dashboard.key -out dashboard.csr
...
...
openssl x509 -req -sha256 -days 365 -in dashboard.csr -signkey dashboard.key -out dashboard.crt

将创建的证书拷贝到其他 node 节点
修改kubernetes-dashboard.yaml文件
1.修改证书挂载方式
volumes:
- name: kubernetes-dashboard-certs
# secret:
# secretName: kubernetes-dashboard-certs
hostPath:
path: /data/apps/kubernetes/certs
type: Directory
2.修改service,端口映射到node上
...
spec:
  type: NodePort
  ports:
    - port: 443
      targetPort: 8443
      nodePort: 31000
  selector:
    k8s-app: kubernetes-dashboard


# kubectl apply -f kubernetes-dashboard.yaml

~~~

配置dashboard令牌

~~~powershell
# cat > token.sh << EOF
#!/bin/bash
if kubectl get sa dashboard-admin -n kube-system &> /dev/null;then
echo -e "\033[33mWARNING: ServiceAccount dashboard-admin exist!\033[0m"
else
kubectl create sa dashboard-admin -n kube-system
kubectl create clusterrolebinding dashboard-admin --clusterrole=cluster-admin --serviceaccount=kube-system:dashboard-admin
fi
EOF

# sh token.sh #生成登录令牌

获取token令牌
kubectl describe secret -n kube-system $(kubectl get secrets -n kube-system | grep dashboard-admin | cut -f1 -d ' ') | grep -E '^token' > login.token

~~~

登录dashboard

~~~powershell
通过 node 节点 ip+端口号访问
# kubectl get svc,pods -n kube-system -o wide
NAME                           TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)                  AGE   SELECTOR
service/kube-dns               ClusterIP   10.99.110.110   <none>        53/UDP,53/TCP,9153/TCP   46h   k8s-app=kube-dns
service/kubernetes-dashboard   NodePort    10.99.129.167   <none>        443:31000/TCP            45h   k8s-app=kubernetes-dashboard

NAME                                       READY   STATUS    RESTARTS   AGE   IP           NODE           NOMINATED NODE   READINESS GATES
pod/coredns-6dcff984f9-gflpx               1/1     Running   1          42h   10.99.24.2   192.168.0.21   <none>           <none>
pod/kubernetes-dashboard-6c87554b5-cf7nt   1/1     Running   0          29h   10.99.86.2   192.168.0.22   <none>           <none>

这里我们可以看到dashboard的pod被调度到192.168.0.22节点上，service对应的nodePort为31000
所以访问链接为：https://192.168.0.22:31000


